<!doctype html>
<html lang="en">

<head>

    
        <!-- Global site tag (gtag.js)  -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-169190162-1"></script>
        <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'UA-169190162-1');
        </script>
    

    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    
<link rel="alternate" type="application/atom+xml" title="Feed for the AdapterHub Blog" href="/blog/atom.xml"/>


    <link rel="icon" type="image/png" href="/static/adapter-bert-head.png" />

    <!-- Font Awesome -->
    <link rel="stylesheet"
          href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.0/css/all.min.css">
    <!-- Pygments -->
    <link rel="stylesheet" href="/pygments.css">
    <!-- CSS -->
    
        <link rel="stylesheet" href="/static/gen/packed.css?c557e741">
    
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/cookieconsent@3/build/cookieconsent.min.css" />
    <!-- JS -->
    
        <script type="text/javascript" src="/static/gen/packed.js?2800c204"></script>
    
    <!-- MathJax -->
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          config: ["MMLorHTML.js"],
          jax: ["input/TeX", "output/HTML-CSS", "output/NativeMML"],
          extensions: ["MathMenu.js", "MathZoom.js"]
        });
    </script>
    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js"></script>

    <title>AdapterHub -  Blog </title>
</head>

<body>

<nav class="navbar navbar-expand-md navbar-light bg-light">
    <div class="container">
        <a class="navbar-brand p-0" href="/">
            <img src="/static/adapter-bert.png" width="28" class="bert"/>
            <span class="align-middle">AdapterHub</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav"
                aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fas fa-bars text-dark" style="font-size:28px"></i>
        </button>
        <div class="collapse navbar-collapse" id="navbarNav">
            <ul class="navbar-nav ml-auto">
                <div class="dropdown-divider d-md-none"></div>
                <li class="nav-item">
                    <a class="nav-link" href="/explore/">
                        <i class="fas fa-binoculars"></i>&nbsp; Explore
                    </a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="https://docs.adapterhub.ml/">
                        <i class="fas fa-book"></i>&nbsp; Docs
                    </a>
                </li>
                <li class="nav-item active">
                    <a class="nav-link" href="/blog/">
                        <i class="fas fa-bullhorn"></i>&nbsp; Blog
                    </a>
                </li>
                <li class="nav-item separator d-none d-md-inline-block"></li>
                <li class="nav-item nav-secondary justify-content-end d-none d-md-inline-block">
                    <a class="nav-link" href="https://github.com/adapter-hub">
                        <i class="fab fa-github"></i>&nbsp;
                    </a>
                </li>
                <li class="nav-item nav-secondary justify-content-end d-none d-md-inline-block">
                    <a class="nav-link" href="https://twitter.com/adapterhub">
                        <i class="fab fa-twitter"></i>&nbsp;
                    </a>
                </li>
            </ul>
        </div>
    </div>
</nav>

<div id="Banner"> </div>

<div id="Header" class="jumbotron jumbotron-fluid py-lg-5">
    <div class="container">
        
<div class="float-right mt-1">
    <a href="/blog/atom.xml" class="btn btn-light btn-sm">
        <i class="fa fa-rss"></i>&nbsp; Feed
    </a>
</div>

<h1>Blog</h1>

    </div>
</div>

<div class="container pb-3 pb-md-5">
    
    

<div class="row posts">
    
    <div class="col-xl-10 col-lg-12 my-lg-3 my-2">
        <a class="btn card bg-light border-0" href="/blog/2025/05/adapters-for-any-transformer/">
            <div class="card-body">
                <h4 class="card-title text-left">
                    Adapters for Any Transformer On the HuggingFace Hub
                    <span class="notice d-none d-lg-block">
                        <i class="fa fa-calendar-alt"></i>&nbsp; 2025-05-21
                        <span class="mr-2">&nbsp;</span>
                        <i class="fa fa-user"></i>&nbsp; The AdapterHub Team
                    </span>
                </h4>
                <p class="notice d-lg-none text-left">
                    <i class="fa fa-calendar-alt"></i>&nbsp; 2025-05-21
                    <span class="mr-2">&nbsp;</span>
                    <i class="fa fa-user"></i>&nbsp; The AdapterHub Team
                </p>
                <p class="card-text text-left">
                    The latest release of Adapters v1.2.0 introduces a new adapter plugin interface that enables adding adapter functionality to nearly any Transformer model.
We go through the details of working with this interface and various additional novelties of the library.

                </p>
            </div>
        </a>
    </div>
    
    <div class="col-xl-10 col-lg-12 my-lg-3 my-2">
        <a class="btn card bg-light border-0" href="/blog/2024/08/adapters-update-reft-qlora-merging-models/">
            <div class="card-body">
                <h4 class="card-title text-left">
                    Adapters Library Updates: ReFT, QLoRA, Merging, New Models &amp; Hub
                    <span class="notice d-none d-lg-block">
                        <i class="fa fa-calendar-alt"></i>&nbsp; 2024-08-10
                        <span class="mr-2">&nbsp;</span>
                        <i class="fa fa-user"></i>&nbsp; Clifton Poth
                    </span>
                </h4>
                <p class="notice d-lg-none text-left">
                    <i class="fa fa-calendar-alt"></i>&nbsp; 2024-08-10
                    <span class="mr-2">&nbsp;</span>
                    <i class="fa fa-user"></i>&nbsp; Clifton Poth
                </p>
                <p class="card-text text-left">
                    Today we are releasing the newest updates in our Adapters library. This post summarizes new features in the latest release as well as selected new features since our initial release in Nov 2023, including new adapter methods, new supported models and Hub updates.

                </p>
            </div>
        </a>
    </div>
    
    <div class="col-xl-10 col-lg-12 my-lg-3 my-2">
        <a class="btn card bg-light border-0" href="/blog/2023/11/introducing-adapters/">
            <div class="card-body">
                <h4 class="card-title text-left">
                    Introducing Adapters
                    <span class="notice d-none d-lg-block">
                        <i class="fa fa-calendar-alt"></i>&nbsp; 2023-11-24
                        <span class="mr-2">&nbsp;</span>
                        <i class="fa fa-user"></i>&nbsp; Hannah Sterz
                    </span>
                </h4>
                <p class="notice d-lg-none text-left">
                    <i class="fa fa-calendar-alt"></i>&nbsp; 2023-11-24
                    <span class="mr-2">&nbsp;</span>
                    <i class="fa fa-user"></i>&nbsp; Hannah Sterz
                </p>
                <p class="card-text text-left">
                    Introducing the new Adapters library the new package that supports adding parameter-efficient fine-tuning methods on top of transformers models and composition to achieve modular setups.

                </p>
            </div>
        </a>
    </div>
    
    <div class="col-xl-10 col-lg-12 my-lg-3 my-2">
        <a class="btn card bg-light border-0" href="/blog/2023/03/adapterhub-v3_2/">
            <div class="card-body">
                <h4 class="card-title text-left">
                    Updates in Adapter-Transformers v3.2
                    <span class="notice d-none d-lg-block">
                        <i class="fa fa-calendar-alt"></i>&nbsp; 2023-03-03
                        <span class="mr-2">&nbsp;</span>
                        <i class="fa fa-user"></i>&nbsp; Hannah Sterz
                    </span>
                </h4>
                <p class="notice d-lg-none text-left">
                    <i class="fa fa-calendar-alt"></i>&nbsp; 2023-03-03
                    <span class="mr-2">&nbsp;</span>
                    <i class="fa fa-user"></i>&nbsp; Hannah Sterz
                </p>
                <p class="card-text text-left">
                    With the newest release of our adapter-transformers library, version 3.2, we add composition blocks for prefix tuning and adapters to several new models.
                </p>
            </div>
        </a>
    </div>
    
    <div class="col-xl-10 col-lg-12 my-lg-3 my-2">
        <a class="btn card bg-light border-0" href="/blog/2022/09/updates-in-adapter-transformers-v3-1/">
            <div class="card-body">
                <h4 class="card-title text-left">
                    Updates in Adapter-Transformers v3.1
                    <span class="notice d-none d-lg-block">
                        <i class="fa fa-calendar-alt"></i>&nbsp; 2022-09-15
                        <span class="mr-2">&nbsp;</span>
                        <i class="fa fa-user"></i>&nbsp; Clifton Poth
                    </span>
                </h4>
                <p class="notice d-lg-none text-left">
                    <i class="fa fa-calendar-alt"></i>&nbsp; 2022-09-15
                    <span class="mr-2">&nbsp;</span>
                    <i class="fa fa-user"></i>&nbsp; Clifton Poth
                </p>
                <p class="card-text text-left">
                    With the newest release of our adapter-transformers library, version 3.1, we take a further step towards integrating the diverse possibilities of parameter-efficient fine-tuning methods by supporting multiple new adapter methods and Transformer architectures.
                </p>
            </div>
        </a>
    </div>
    
    <div class="col-xl-10 col-lg-12 my-lg-3 my-2">
        <a class="btn card bg-light border-0" href="/blog/2022/03/adapter-transformers-v3-unifying-efficient-fine-tuning/">
            <div class="card-body">
                <h4 class="card-title text-left">
                    Adapter-Transformers v3 - Unifying Efficient Fine-Tuning
                    <span class="notice d-none d-lg-block">
                        <i class="fa fa-calendar-alt"></i>&nbsp; 2022-03-21
                        <span class="mr-2">&nbsp;</span>
                        <i class="fa fa-user"></i>&nbsp; Clifton Poth
                    </span>
                </h4>
                <p class="notice d-lg-none text-left">
                    <i class="fa fa-calendar-alt"></i>&nbsp; 2022-03-21
                    <span class="mr-2">&nbsp;</span>
                    <i class="fa fa-user"></i>&nbsp; Clifton Poth
                </p>
                <p class="card-text text-left">
                    With the release of version 3.0 of adapter-transformers today, we&#39;re taking the first steps at integrating the grown and diversified landscape of efficient fine-tuning methods. Version 3.0 adds support for a first batch of recently proposed methods, including Prefix Tuning, Parallel adapters, Mix-and-Match adapters and Compacters. Further, improvements and changes to various aspects of the library are introduced.
                </p>
            </div>
        </a>
    </div>
    
    <div class="col-xl-10 col-lg-12 my-lg-3 my-2">
        <a class="btn card bg-light border-0" href="/blog/2021/04/adapters-for-generative-and-seq2seq-models-in-nlp/">
            <div class="card-body">
                <h4 class="card-title text-left">
                    Adapters for Generative and Seq2Seq Models in NLP
                    <span class="notice d-none d-lg-block">
                        <i class="fa fa-calendar-alt"></i>&nbsp; 2021-04-29
                        <span class="mr-2">&nbsp;</span>
                        <i class="fa fa-user"></i>&nbsp; Hannah Sterz*
                    </span>
                </h4>
                <p class="notice d-lg-none text-left">
                    <i class="fa fa-calendar-alt"></i>&nbsp; 2021-04-29
                    <span class="mr-2">&nbsp;</span>
                    <i class="fa fa-user"></i>&nbsp; Hannah Sterz*
                </p>
                <p class="card-text text-left">
                    Adapters have proven to be an efficient alternative to fully finetung models. The version 2.0 of the AdapterHub framework includes adapters for the BART and GPT2 models.

                </p>
            </div>
        </a>
    </div>
    
    <div class="col-xl-10 col-lg-12 my-lg-3 my-2">
        <a class="btn card bg-light border-0" href="/blog/2021/04/version-2-of-adapterhub-released/">
            <div class="card-body">
                <h4 class="card-title text-left">
                    Version 2 of AdapterHub Released
                    <span class="notice d-none d-lg-block">
                        <i class="fa fa-calendar-alt"></i>&nbsp; 2021-04-29
                        <span class="mr-2">&nbsp;</span>
                        <i class="fa fa-user"></i>&nbsp; Clifton Poth
                    </span>
                </h4>
                <p class="notice d-lg-none text-left">
                    <i class="fa fa-calendar-alt"></i>&nbsp; 2021-04-29
                    <span class="mr-2">&nbsp;</span>
                    <i class="fa fa-user"></i>&nbsp; Clifton Poth
                </p>
                <p class="card-text text-left">
                    Today, we are releasing version 2 of the AdapterHub. This release introduces several exciting new ways for composing adapters through composition blocks, including AdapterFusion, parallel inference, Adapter stacking, and combinations thereof. Furthermore, we now support new Transformer architectures such as GPT-2 and BART.
                </p>
            </div>
        </a>
    </div>
    
    <div class="col-xl-10 col-lg-12 my-lg-3 my-2">
        <a class="btn card bg-light border-0" href="/blog/2020/11/adapting-transformers-with-adapterhub/">
            <div class="card-body">
                <h4 class="card-title text-left">
                    Adapting Transformers with AdapterHub
                    <span class="notice d-none d-lg-block">
                        <i class="fa fa-calendar-alt"></i>&nbsp; 2020-11-17
                        <span class="mr-2">&nbsp;</span>
                        <i class="fa fa-user"></i>&nbsp; Clifton Poth
                    </span>
                </h4>
                <p class="notice d-lg-none text-left">
                    <i class="fa fa-calendar-alt"></i>&nbsp; 2020-11-17
                    <span class="mr-2">&nbsp;</span>
                    <i class="fa fa-user"></i>&nbsp; Clifton Poth
                </p>
                <p class="card-text text-left">
                    Adapters are a new, efficient and composable alternative to full fine-tuning of pre-trained language models.
AdapterHub makes working with adapters accessible by providing a framework for training, sharing, discovering and consuming adapter modules.
This post provides an extensive overview.

                </p>
            </div>
        </a>
    </div>
    
</div>


</div>

<footer>
    <div class="container">
        <p class="float-md-right text-center text-md-right">
            <a href="https://arxiv.org/abs/2311.11077" target="_blank">Paper</a>
            <!--<span class="text-black-30 px-1">|</span>
            <a href="/imprint-privacy/">Imprint & Privacy</a>-->
        </p>
        <p class="text-muted text-center text-md-left">Brought to you with ❤️ by the AdapterHub Team</p>
    </div>
</footer>

<script>
    document.addEventListener('DOMContentLoaded', function (event) {
        codecopy('pre') // your code tag selector!
        $('.activate-tooltip').tooltip();   // bootstrap tooltips
    })
</script>
<script src="https://cdn.jsdelivr.net/npm/cookieconsent@3/build/cookieconsent.min.js" data-cfasync="false"></script>
<script>
    window.cookieconsent.initialise({
    "palette": {
        "popup": {
        "background": "#d7f0f4"
        },
        "button": {
        "background": "#39b3c6",
        "text": "#ffffff"
        }
    },
    "theme": "classic"
    });
</script>
</body>
</html>