{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4PyaAqxoaBgT"
   },
   "source": [
    "# **AdapterHub** quickstart example for **inference**\n",
    "\n",
    "First, install adapter-transformers from github/master, import the required modules and load a standard Bert model and tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GQwP-DPOvJQl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/adapter-hub/adapter-transformers.git@v2\n",
      "  Cloning https://github.com/adapter-hub/adapter-transformers.git (to revision v2) to c:\\users\\hster\\appdata\\local\\temp\\pip-req-build-3vg4fz97\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hster\\anaconda3\\lib\\site-packages (from adapter-transformers==2.0.0a1) (1.20.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\hster\\anaconda3\\lib\\site-packages (from adapter-transformers==2.0.0a1) (3.0.10)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\hster\\anaconda3\\lib\\site-packages (from adapter-transformers==2.0.0a1) (0.0.38)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\hster\\anaconda3\\lib\\site-packages (from adapter-transformers==2.0.0a1) (0.10.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hster\\anaconda3\\lib\\site-packages (from adapter-transformers==2.0.0a1) (2020.4.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hster\\anaconda3\\lib\\site-packages (from adapter-transformers==2.0.0a1) (4.31.1)\n",
      "Requirement already satisfied: requests in c:\\users\\hster\\anaconda3\\lib\\site-packages (from adapter-transformers==2.0.0a1) (2.21.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hster\\anaconda3\\lib\\site-packages (from adapter-transformers==2.0.0a1) (19.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\hster\\anaconda3\\lib\\site-packages (from adapter-transformers==2.0.0a1) (0.0.0)\n",
      "Requirement already satisfied: zipp>=0.3.2 in c:\\users\\hster\\anaconda3\\lib\\site-packages (from importlib-metadata->adapter-transformers==2.0.0a1) (0.3.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\hster\\anaconda3\\lib\\site-packages (from packaging->adapter-transformers==2.0.0a1) (2.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\hster\\anaconda3\\lib\\site-packages (from packaging->adapter-transformers==2.0.0a1) (1.12.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\hster\\anaconda3\\lib\\site-packages (from requests->adapter-transformers==2.0.0a1) (1.24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hster\\anaconda3\\lib\\site-packages (from requests->adapter-transformers==2.0.0a1) (2020.6.20)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\hster\\anaconda3\\lib\\site-packages (from requests->adapter-transformers==2.0.0a1) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\hster\\anaconda3\\lib\\site-packages (from requests->adapter-transformers==2.0.0a1) (3.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\hster\\anaconda3\\lib\\site-packages (from sacremoses->adapter-transformers==2.0.0a1) (0.14.1)\n",
      "Requirement already satisfied: click in c:\\users\\hster\\anaconda3\\lib\\site-packages (from sacremoses->adapter-transformers==2.0.0a1) (7.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\hster\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/adapter-hub/adapter-transformers.git@v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "co43JhjxZ7lT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdapterType\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NaCwIyxKC49k"
   },
   "source": [
    "Loading existing adapters from our repository is as simple as adding one additional line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CqNGQxN_C5L8"
   },
   "outputs": [],
   "source": [
    "model.load_adapter(\"sentiment/sst-2@ukp\")\n",
    "model.set_active_adapters(\"sst-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TNOYYo3MDfOK"
   },
   "source": [
    "The [SST adapter](https://adapterhub.ml/adapters/ukp/bert-base-uncased-sst_pfeiffer/) is light-weight: it is only 3MB! At the same time, it achieves results that are [on-par with fully fine-tuned BERT](https://arxiv.org/abs/2007.07779). We can now leverage SST adapter to predict the sentiment of sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tXHpbKVwwiuz"
   },
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "  token_ids = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentence))\n",
    "  input_tensor = torch.tensor([token_ids])\n",
    "\n",
    "  # predict output tensor\n",
    "  outputs = model(input_tensor)\n",
    "\n",
    "  # retrieve the predicted class label\n",
    "  return 'positive' if 1 == torch.argmax(outputs[0]).item() else 'negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4v70QiODz8VT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Those who find ugly meanings in beautiful things are corrupt without being charming.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HieI-Svs0BPP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"There are slow and repetitive parts, but it has just enough spice to keep it interesting.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Adapter-Quickstart-Inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
